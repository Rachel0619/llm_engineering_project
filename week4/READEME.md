## Notes

### Comparing the following features of LLMs

- Open-source or closed
- Release date and knowledge cut-off
- Parameters
- Training tokens
- Context length

### Comparing the following costs of LLMs

- Inference cost (API charge, subscription, runtime compute)
- Training cost
- Build cost
- Time to Market
- Rate limits
- Speed
- Latency
- License

### The Chinchilla Scaling Law

Number of parameters is proportional to the number of training tokens

